{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset -fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import linear_model, tree\n",
    "from sklearn.model_selection import train_test_split,cross_val_score, cross_val_predict,GridSearchCV,RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    " \n",
    "from sklearn.metrics import roc_curve, confusion_matrix,precision_recall_curve,roc_auc_score\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score \n",
    "\n",
    "import xgboost as xgb # note for installation use py-xgboost in conda\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('application_train.csv')\n",
    "test = pd.read_csv('application_test.csv')\n",
    "test['target'] = -999\n",
    "train.columns = train.columns.str.lower()\n",
    "test.columns = test.columns.str.lower()\n",
    "\n",
    "train['dataset'] = 'train'\n",
    "test['dataset'] = 'test'\n",
    "\n",
    "X = pd.concat([train,test],sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[X.dataset == 'train'].drop(['target', 'dataset'], axis=1)\n",
    "X_test = X[X.dataset == 'test'].drop(['target', 'dataset'], axis=1)\n",
    "y_train = X[X.dataset == 'train'].target\n",
    "y_test = X[X.dataset == 'test'].target\n",
    "\n",
    "X.drop('dataset', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_threshold = 20\n",
    "missing = pd.DataFrame(X.isnull().sum(),columns=['Number'])\n",
    "missing['Percentage'] = round(missing.Number/X.shape[0]*100,2)\n",
    "missing[missing.Percentage>20]\n",
    "to_remove = missing[missing.Percentage>drop_threshold].index.tolist()\n",
    "\n",
    "X.drop(to_remove, axis=1, inplace=True)\n",
    "X_train.drop(to_remove, axis=1, inplace=True)\n",
    "X_test.drop(to_remove, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (307511, 71)\n",
      "X_test shape: (48744, 71)\n",
      "y_train shape: (307511,)\n",
      "y_test shape: (48744,)\n",
      "X shape: (356255, 72)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)\n",
    "print('X shape:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = list(X.columns[X.dtypes!=object])\n",
    "num_features.remove('target')\n",
    "cat_features = list(X.columns[X.dtypes==object])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Pipline for numerical features\n",
    "num_pipeline = Pipeline([\n",
    "    #('imputer_num', KNNImputer(n_neighbors=2, weights='uniform')),\n",
    "    ('imputer_num', SimpleImputer(strategy='median')),\n",
    "    ('std_scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline for categorical features \n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer_cat', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('1hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete pipeline\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_pipeline, num_features),\n",
    "    ('cat', cat_pipeline, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a full pipeline with our preprocessor and a LogisticRegression Classifier\n",
    "pipe_logreg = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('logreg', LogisticRegression(max_iter=1000))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   53.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:  1.6min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:  2.2min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:  3.1min remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  4.0min finished\n"
     ]
    }
   ],
   "source": [
    "# Making predictions on the training set using cross validation as well as calculating the probabilities \n",
    "y_train_predicted = cross_val_predict(pipe_logreg, X_train, y_train, cv=5, verbose=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross validation scores:\n",
      "-------------------------\n",
      "Accuracy: 0.92\n",
      "Recall: 0.01\n",
      "Precision: 0.49\n"
     ]
    }
   ],
   "source": [
    "# Calculating the accuracy for the LogisticRegression Classifier \n",
    "print('Cross validation scores:')\n",
    "print('-------------------------')\n",
    "print(\"Accuracy: {:.2f}\".format(accuracy_score(y_train, y_train_predicted)))\n",
    "print(\"Recall: {:.2f}\".format(recall_score(y_train, y_train_predicted)))\n",
    "print(\"Precision: {:.2f}\".format(precision_score(y_train, y_train_predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 356255 entries, 0 to 48743\n",
      "Data columns (total 11 columns):\n",
      "code_gender                   356255 non-null object\n",
      "flag_own_car                  356255 non-null object\n",
      "flag_own_realty               356255 non-null object\n",
      "name_contract_type            356255 non-null object\n",
      "name_education_type           356255 non-null object\n",
      "name_family_status            356255 non-null object\n",
      "name_housing_type             356255 non-null object\n",
      "name_income_type              356255 non-null object\n",
      "name_type_suite               354052 non-null object\n",
      "organization_type             356255 non-null object\n",
      "weekday_appr_process_start    356255 non-null object\n",
      "dtypes: object(11)\n",
      "memory usage: 32.6+ MB\n"
     ]
    }
   ],
   "source": [
    "X[cat_features].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unaccompanied', 'Family', 'Spouse, partner', 'Children',\n",
       "       'Other_A', nan, 'Other_B', 'Group of people'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[cat_features].name_type_suite.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python [conda env:nf] *",
   "language": "python",
   "name": "conda-env-nf-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
